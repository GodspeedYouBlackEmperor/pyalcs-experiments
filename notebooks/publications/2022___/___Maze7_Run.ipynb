{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from utils.run_utils import Runner\n",
    "\n",
    "import gym\n",
    "import gym_maze\n",
    "\n",
    "from lcs.agents import Agent\n",
    "from lcs.agents.acs2 import ACS2, Configuration as CFG_ACS2, ClassifiersList\n",
    "from lcs.agents.acs2er import ACS2ER, Configuration as CFG_ACS2ER, ReplayMemory, ReplayMemorySample\n",
    "from lcs.agents.acs2eer import ACS2EER, Configuration as CFG_ACS2EER, TrialReplayMemory\n",
    "from lcs.metrics import population_metrics\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = \"Maze7-v0\" \n",
    "EXPLORE_EXPLOIT_TRIALS = 10000\n",
    "\n",
    "# The size of ER replay memory buffer\n",
    "ER_BUFFER_SIZE = 10000\n",
    "# The minimum number of samples of ER replay memory buffer to start replying samples (warm-up phase)\n",
    "ER_BUFFER_MIN_SAMPLES = 1000\n",
    "# The number of samples to be replayed druing ER phase\n",
    "ER_SAMPLES_NUMBER_LIST = [3]\n",
    "\n",
    "EER_BUFFER_SIZE = 1000\n",
    "EER_BUFFER_MIN_SAMPLES = 25\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "REPEAT_START = 1\n",
    "REPEAT = 10\n",
    "\n",
    "EXPERIMENT_NAME = \"MAZE_7_EXP_1\" # Please edit if running new experiment to do not override saved results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner('MAZE', EXPERIMENT_NAME, MAZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE_PATH = 0\n",
    "MAZE_REWARD = 9\n",
    "\n",
    "optimal_paths_env = gym.make(MAZE)\n",
    "matrix = optimal_paths_env.matrix\n",
    "X = matrix.shape[1]\n",
    "Y = matrix.shape[0]\n",
    "\n",
    "def get_reward_pos():\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            if(matrix[i, j] == MAZE_REWARD):\n",
    "                return(i, j)\n",
    "\n",
    "def get_possible_neighbour_cords(pos_y, pos_x):\n",
    "    n = ((pos_y - 1, pos_x), 4)\n",
    "    ne = ((pos_y - 1, pos_x + 1), 5)\n",
    "    e = ((pos_y, pos_x + 1), 6)\n",
    "    se = ((pos_y + 1, pos_x + 1), 7)\n",
    "    s = ((pos_y + 1, pos_x), 0)\n",
    "    sw = ((pos_y + 1, pos_x - 1), 1)\n",
    "    w = ((pos_y, pos_x - 1), 2)\n",
    "    nw = ((pos_y - 1, pos_x - 1), 3)\n",
    "\n",
    "    return [n, ne, e, se, s, sw, w, nw]\n",
    "\n",
    "    \n",
    "optimal_actions = []\n",
    "\n",
    "root_node = get_reward_pos()\n",
    "\n",
    "def is_included(cords, level):\n",
    "    return any(op_cords[0] == cords[0] and op_cords[1] == cords[1] and level != op_level for op_cords, _, op_level in optimal_actions)\n",
    "\n",
    "\n",
    "def get_optimal_actions_to(node, level):\n",
    "    neighbour_cords = get_possible_neighbour_cords(node[0], node[1])\n",
    "\n",
    "    next_level_cords = []\n",
    "    for (pos_y, pos_x), action in neighbour_cords:\n",
    "        if (not is_included((pos_y, pos_x), level)) and matrix[pos_y, pos_x] == MAZE_PATH:\n",
    "            optimal_actions.append(((pos_y, pos_x), action, level))\n",
    "            next_level_cords.append((pos_y, pos_x))\n",
    "\n",
    "    return next_level_cords\n",
    "\n",
    "LEVEL = 0\n",
    "next_level_cords = get_optimal_actions_to(root_node, LEVEL)\n",
    "\n",
    "while len(next_level_cords) > 0:\n",
    "    LEVEL += 1\n",
    "    new_next_level_cords = []\n",
    "    for nlc in next_level_cords:\n",
    "        new_next_level_cords += get_optimal_actions_to(nlc, LEVEL)\n",
    "\n",
    "    next_level_cords = new_next_level_cords\n",
    "\n",
    "positions_actions = defaultdict(set)\n",
    "for cords, a, _ in optimal_actions: positions_actions[cords].add(a)\n",
    "\n",
    "positions_actions = positions_actions.items()\n",
    "POSITIONS_OPTIMAL_ACTIONS = list(map(lambda pa: (optimal_paths_env.env.maze.perception(pa[0]), list(pa[1])), positions_actions))\n",
    "POSITIONS_OPTIMAL_ACTIONS_LENGTH = len(POSITIONS_OPTIMAL_ACTIONS)\n",
    "\n",
    "\n",
    "\n",
    "def _maze_optimal(classifiers) -> float:\n",
    "    nr_correct = 0\n",
    "\n",
    "    for p0, optimal_actions_list in POSITIONS_OPTIMAL_ACTIONS:\n",
    "        match_set = classifiers.form_match_set(p0)\n",
    "        cl = match_set.get_best_classifier()\n",
    "\n",
    "        if cl is not None and optimal_actions_list.count(cl.action) > 0:\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / POSITIONS_OPTIMAL_ACTIONS_LENGTH * 100.0\n",
    "\n",
    "\n",
    "def _maze_optimal_reliable(classifiers) -> float:\n",
    "    return _maze_optimal(ClassifiersList(*[c for c in classifiers if c.is_reliable()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_transitions():\n",
    "    knowledge_env = gym.make(MAZE)\n",
    "    transitions = knowledge_env.env.get_transitions()\n",
    "    transitions = list(map(lambda t: [knowledge_env.env.maze.perception(t[0]), t[1], knowledge_env.env.maze.perception(t[2])], transitions))\n",
    "\n",
    "    return transitions\n",
    "\n",
    "TRANSITIONS = _get_transitions()\n",
    "TRANSITIONS_LENGTH = len(TRANSITIONS)\n",
    "\n",
    "def _maze_knowledge(population) -> float:\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for p0, action, p1 in TRANSITIONS:\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / TRANSITIONS_LENGTH * 100.0\n",
    "\n",
    "def _maze_specificity(population) -> float:\n",
    "    pop_len = len(population)\n",
    "    if(pop_len) == 0:\n",
    "        return 0\n",
    "    return sum(map(lambda c: c.specificity, population)) / pop_len\n",
    "\n",
    "def _maze_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': _maze_knowledge(pop),\n",
    "        \"specificity\": _maze_specificity(agent.population),\n",
    "        \"optimal\": _maze_optimal(agent.population),\n",
    "        \"optimal_reliable\": _maze_optimal_reliable(agent.population)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_experiment(agent, path):\n",
    "    runner.run_experiment_explore_exploit(agent, gym.make(MAZE), EXPLORE_EXPLOIT_TRIALS, path)\n",
    "\n",
    "def run_acs2_experiment():\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2(cfg)\n",
    "\n",
    "        _run_experiment(agent, f'{i}')\n",
    "\n",
    "def _run_acs2er_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2ER(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=ER_BUFFER_SIZE,\n",
    "            er_min_samples=ER_BUFFER_MIN_SAMPLES,\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2ER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-ER', f'{i}'))\n",
    "\n",
    "def run_acs2er_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2ER - {er_samples_number}\")\n",
    "        _run_acs2er_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2ER - {er_samples_number}\")\n",
    "\n",
    "\n",
    "def _run_acs2eer_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2EER(           \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=EER_BUFFER_SIZE,\n",
    "            er_min_samples=int(EER_BUFFER_MIN_SAMPLES),\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2EER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-EER', f'{i}'))\n",
    "\n",
    "def run_acs2eer_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2EER - {er_samples_number}\")\n",
    "        _run_acs2eer_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2EER - {er_samples_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 20, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.0041018000000008215, 'knowledge': 0.0, 'specificity': 0.2757352941176471, 'optimal': 80.0, 'optimal_reliable': 0.0, 'population': 34, 'numerosity': 34, 'reliable': 0}\n",
      "INFO:lcs.agents.Agent:{'trial': 40, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.0018151000000017348, 'knowledge': 7.142857142857142, 'specificity': 0.24702380952380953, 'optimal': 80.0, 'optimal_reliable': 20.0, 'population': 42, 'numerosity': 42, 'reliable': 1}\n",
      "INFO:lcs.agents.Agent:{'trial': 60, 'steps_in_trial': 9, 'reward': 1000, 'perf_time': 0.010495800000001054, 'knowledge': 7.142857142857142, 'specificity': 0.23, 'optimal': 80.0, 'optimal_reliable': 20.0, 'population': 50, 'numerosity': 50, 'reliable': 1}\n",
      "INFO:lcs.agents.Agent:{'trial': 80, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.004288999999999987, 'knowledge': 14.285714285714285, 'specificity': 0.22596153846153846, 'optimal': 80.0, 'optimal_reliable': 40.0, 'population': 52, 'numerosity': 52, 'reliable': 2}\n",
      "INFO:lcs.agents.Agent:{'trial': 100, 'steps_in_trial': 6, 'reward': 1000, 'perf_time': 0.009862599999998167, 'knowledge': 21.428571428571427, 'specificity': 0.22321428571428573, 'optimal': 80.0, 'optimal_reliable': 60.0, 'population': 56, 'numerosity': 56, 'reliable': 3}\n",
      "INFO:lcs.agents.Agent:{'trial': 120, 'steps_in_trial': 1, 'reward': 1000, 'perf_time': 0.000973799999997027, 'knowledge': 28.57142857142857, 'specificity': 0.2236842105263158, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 57, 'numerosity': 57, 'reliable': 4}\n",
      "INFO:lcs.agents.Agent:{'trial': 140, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.0027223999999996806, 'knowledge': 35.714285714285715, 'specificity': 0.21875, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 60, 'numerosity': 60, 'reliable': 5}\n",
      "INFO:lcs.agents.Agent:{'trial': 160, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.0030257999999996343, 'knowledge': 35.714285714285715, 'specificity': 0.2192622950819672, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 61, 'numerosity': 61, 'reliable': 5}\n",
      "INFO:lcs.agents.Agent:{'trial': 180, 'steps_in_trial': 6, 'reward': 1000, 'perf_time': 0.004169400000002099, 'knowledge': 42.857142857142854, 'specificity': 0.21975806451612903, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 62, 'numerosity': 62, 'reliable': 6}\n",
      "INFO:lcs.agents.Agent:{'trial': 200, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.00727589999999978, 'knowledge': 42.857142857142854, 'specificity': 0.22023809523809523, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 63, 'numerosity': 63, 'reliable': 8}\n"
     ]
    }
   ],
   "source": [
    "run_acs2_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2ER Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 20, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.03423069999999839, 'knowledge': 0.0, 'specificity': 0.20246478873239437, 'optimal': 80.0, 'optimal_reliable': 0.0, 'population': 71, 'numerosity': 71, 'reliable': 0}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2ER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 40, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.025883400000001444, 'knowledge': 7.142857142857142, 'specificity': 0.1971153846153846, 'optimal': 80.0, 'optimal_reliable': 20.0, 'population': 78, 'numerosity': 78, 'reliable': 4}\n",
      "INFO:lcs.agents.Agent:{'trial': 60, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.03071570000000179, 'knowledge': 35.714285714285715, 'specificity': 0.20121951219512196, 'optimal': 80.0, 'optimal_reliable': 40.0, 'population': 82, 'numerosity': 82, 'reliable': 11}\n",
      "INFO:lcs.agents.Agent:{'trial': 80, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.018974400000001168, 'knowledge': 50.0, 'specificity': 0.2052469135802469, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 81, 'numerosity': 81, 'reliable': 19}\n",
      "INFO:lcs.agents.Agent:{'trial': 100, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.015597499999998377, 'knowledge': 64.28571428571429, 'specificity': 0.20579268292682926, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 82, 'numerosity': 82, 'reliable': 27}\n",
      "INFO:lcs.agents.Agent:{'trial': 120, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.02701060000000055, 'knowledge': 64.28571428571429, 'specificity': 0.20833333333333334, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 81, 'numerosity': 81, 'reliable': 31}\n",
      "INFO:lcs.agents.Agent:{'trial': 140, 'steps_in_trial': 1, 'reward': 1000, 'perf_time': 0.007730300000002188, 'knowledge': 64.28571428571429, 'specificity': 0.20987654320987653, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 81, 'numerosity': 81, 'reliable': 34}\n",
      "INFO:lcs.agents.Agent:{'trial': 160, 'steps_in_trial': 11, 'reward': 1000, 'perf_time': 0.07196300000000022, 'knowledge': 78.57142857142857, 'specificity': 0.2125, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 80, 'numerosity': 80, 'reliable': 39}\n",
      "INFO:lcs.agents.Agent:{'trial': 180, 'steps_in_trial': 8, 'reward': 1000, 'perf_time': 0.04346169999999816, 'knowledge': 85.71428571428571, 'specificity': 0.2125, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 80, 'numerosity': 80, 'reliable': 42}\n",
      "INFO:lcs.agents.Agent:{'trial': 200, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.05679230000000146, 'knowledge': 85.71428571428571, 'specificity': 0.2125, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 80, 'numerosity': 80, 'reliable': 45}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2ER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2er_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2EER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 20, 'steps_in_trial': 19, 'reward': 1000, 'perf_time': 0.05458810000000014, 'knowledge': 0.0, 'specificity': 0.22857142857142856, 'optimal': 60.0, 'optimal_reliable': 0.0, 'population': 35, 'numerosity': 35, 'reliable': 0}\n",
      "INFO:lcs.agents.Agent:{'trial': 40, 'steps_in_trial': 6, 'reward': 1000, 'perf_time': 0.06076730000000197, 'knowledge': 85.71428571428571, 'specificity': 0.20978260869565218, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 115, 'numerosity': 115, 'reliable': 37}\n",
      "INFO:lcs.agents.Agent:{'trial': 60, 'steps_in_trial': 21, 'reward': 1000, 'perf_time': 0.28393520000000194, 'knowledge': 92.85714285714286, 'specificity': 0.21238938053097345, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 113, 'numerosity': 113, 'reliable': 51}\n",
      "INFO:lcs.agents.Agent:{'trial': 80, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.03144720000000234, 'knowledge': 92.85714285714286, 'specificity': 0.21621621621621623, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 111, 'numerosity': 111, 'reliable': 67}\n",
      "INFO:lcs.agents.Agent:{'trial': 100, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.02189050000000492, 'knowledge': 100.0, 'specificity': 0.22106481481481483, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 108, 'numerosity': 108, 'reliable': 85}\n",
      "INFO:lcs.agents.Agent:{'trial': 120, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.01598080000000124, 'knowledge': 100.0, 'specificity': 0.22106481481481483, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 108, 'numerosity': 108, 'reliable': 94}\n",
      "INFO:lcs.agents.Agent:{'trial': 140, 'steps_in_trial': 8, 'reward': 1000, 'perf_time': 0.02424989999999383, 'knowledge': 100.0, 'specificity': 0.22106481481481483, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 108, 'numerosity': 108, 'reliable': 99}\n",
      "INFO:lcs.agents.Agent:{'trial': 160, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.07587130000000286, 'knowledge': 100.0, 'specificity': 0.22106481481481483, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 108, 'numerosity': 108, 'reliable': 103}\n",
      "INFO:lcs.agents.Agent:{'trial': 180, 'steps_in_trial': 8, 'reward': 1000, 'perf_time': 0.08926549999999622, 'knowledge': 100.0, 'specificity': 0.22106481481481483, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 108, 'numerosity': 108, 'reliable': 103}\n",
      "INFO:lcs.agents.Agent:{'trial': 200, 'steps_in_trial': 6, 'reward': 1000, 'perf_time': 0.03154609999999991, 'knowledge': 100.0, 'specificity': 0.22106481481481483, 'optimal': 80.0, 'optimal_reliable': 80.0, 'population': 108, 'numerosity': 108, 'reliable': 104}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2EER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2eer_experiments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec208294d083f15f7ed14d725810d00783612c76b14ab5c82bea0e3fdbc09b32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
