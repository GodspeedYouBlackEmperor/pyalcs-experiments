{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from utils.run_utils import Runner\n",
    "\n",
    "import gym\n",
    "import gym_maze\n",
    "\n",
    "from lcs.agents import Agent\n",
    "from lcs.agents.acs2 import ACS2, Configuration as CFG_ACS2, ClassifiersList\n",
    "from lcs.agents.acs2er import ACS2ER, Configuration as CFG_ACS2ER, ReplayMemory, ReplayMemorySample\n",
    "from lcs.agents.acs2eer import ACS2EER, Configuration as CFG_ACS2EER, TrialReplayMemory\n",
    "from lcs.metrics import population_metrics\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = \"MazeZ-v0\" \n",
    "EXPLORE_EXPLOIT_TRIALS = 10000\n",
    "\n",
    "# The size of ER replay memory buffer\n",
    "ER_BUFFER_SIZE = 10000\n",
    "# The minimum number of samples of ER replay memory buffer to start replying samples (warm-up phase)\n",
    "ER_BUFFER_MIN_SAMPLES = 1000\n",
    "# The number of samples to be replayed druing ER phase\n",
    "ER_SAMPLES_NUMBER_LIST = [3]\n",
    "\n",
    "EER_BUFFER_SIZE = 1000\n",
    "EER_BUFFER_MIN_SAMPLES = 25\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "REPEAT_START = 1\n",
    "REPEAT = 1\n",
    "\n",
    "EXPERIMENT_NAME = \"MAZE_Y_EXP_1\" # Please edit if running new experiment to do not override saved results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner('MAZE', EXPERIMENT_NAME, MAZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE_PATH = 0\n",
    "MAZE_REWARD = 9\n",
    "\n",
    "optimal_paths_env = gym.make(MAZE)\n",
    "matrix = optimal_paths_env.matrix\n",
    "X = matrix.shape[1]\n",
    "Y = matrix.shape[0]\n",
    "\n",
    "def get_reward_pos():\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            if(matrix[i, j] == MAZE_REWARD):\n",
    "                return(i, j)\n",
    "\n",
    "def get_possible_neighbour_cords(pos_y, pos_x):\n",
    "    n = ((pos_y - 1, pos_x), 4)\n",
    "    ne = ((pos_y - 1, pos_x + 1), 5)\n",
    "    e = ((pos_y, pos_x + 1), 6)\n",
    "    se = ((pos_y + 1, pos_x + 1), 7)\n",
    "    s = ((pos_y + 1, pos_x), 0)\n",
    "    sw = ((pos_y + 1, pos_x - 1), 1)\n",
    "    w = ((pos_y, pos_x - 1), 2)\n",
    "    nw = ((pos_y - 1, pos_x - 1), 3)\n",
    "\n",
    "    return [n, ne, e, se, s, sw, w, nw]\n",
    "\n",
    "    \n",
    "optimal_actions = []\n",
    "\n",
    "root_node = get_reward_pos()\n",
    "\n",
    "def is_included(cords, level):\n",
    "    return any(op_cords[0] == cords[0] and op_cords[1] == cords[1] and level != op_level for op_cords, _, op_level in optimal_actions)\n",
    "\n",
    "\n",
    "def get_optimal_actions_to(node, level):\n",
    "    neighbour_cords = get_possible_neighbour_cords(node[0], node[1])\n",
    "\n",
    "    next_level_cords = []\n",
    "    for (pos_y, pos_x), action in neighbour_cords:\n",
    "        if (not is_included((pos_y, pos_x), level)) and matrix[pos_y, pos_x] == MAZE_PATH:\n",
    "            optimal_actions.append(((pos_y, pos_x), action, level))\n",
    "            next_level_cords.append((pos_y, pos_x))\n",
    "\n",
    "    return next_level_cords\n",
    "\n",
    "LEVEL = 0\n",
    "next_level_cords = get_optimal_actions_to(root_node, LEVEL)\n",
    "\n",
    "while len(next_level_cords) > 0:\n",
    "    LEVEL += 1\n",
    "    new_next_level_cords = []\n",
    "    for nlc in next_level_cords:\n",
    "        new_next_level_cords += get_optimal_actions_to(nlc, LEVEL)\n",
    "\n",
    "    next_level_cords = new_next_level_cords\n",
    "\n",
    "positions_actions = defaultdict(set)\n",
    "for cords, a, _ in optimal_actions: positions_actions[cords].add(a)\n",
    "\n",
    "positions_actions = positions_actions.items()\n",
    "POSITIONS_OPTIMAL_ACTIONS = list(map(lambda pa: (optimal_paths_env.env.maze.perception(pa[0]), list(pa[1])), positions_actions))\n",
    "POSITIONS_OPTIMAL_ACTIONS_LENGTH = len(POSITIONS_OPTIMAL_ACTIONS)\n",
    "\n",
    "\n",
    "\n",
    "def _maze_optimal(classifiers) -> float:\n",
    "    nr_correct = 0\n",
    "\n",
    "    for p0, optimal_actions_list in POSITIONS_OPTIMAL_ACTIONS:\n",
    "        match_set = classifiers.form_match_set(p0)\n",
    "        cl = match_set.get_best_classifier()\n",
    "\n",
    "        if cl is not None and optimal_actions_list.count(cl.action) > 0:\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / POSITIONS_OPTIMAL_ACTIONS_LENGTH * 100.0\n",
    "\n",
    "\n",
    "def _maze_optimal_reliable(classifiers) -> float:\n",
    "    return _maze_optimal(ClassifiersList(*[c for c in classifiers if c.is_reliable()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_transitions():\n",
    "    knowledge_env = gym.make(MAZE)\n",
    "    transitions = knowledge_env.env.get_transitions()\n",
    "    transitions = list(map(lambda t: [knowledge_env.env.maze.perception(t[0]), t[1], knowledge_env.env.maze.perception(t[2])], transitions))\n",
    "\n",
    "    return transitions\n",
    "\n",
    "TRANSITIONS = _get_transitions()\n",
    "TRANSITIONS_LENGTH = len(TRANSITIONS)\n",
    "\n",
    "def _maze_knowledge(population) -> float:\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for p0, action, p1 in TRANSITIONS:\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / TRANSITIONS_LENGTH * 100.0\n",
    "\n",
    "def _maze_specificity(population) -> float:\n",
    "    pop_len = len(population)\n",
    "    if(pop_len) == 0:\n",
    "        return 0\n",
    "    return sum(map(lambda c: c.specificity, population)) / pop_len\n",
    "\n",
    "def _maze_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': _maze_knowledge(pop),\n",
    "        \"specificity\": _maze_specificity(agent.population),\n",
    "        \"optimal\": _maze_optimal(agent.population),\n",
    "        \"optimal_reliable\": _maze_optimal_reliable(agent.population)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_experiment(agent, path):\n",
    "    runner.run_experiment_explore_exploit(agent, gym.make(MAZE), EXPLORE_EXPLOIT_TRIALS, path)\n",
    "\n",
    "def run_acs2_experiment():\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2(cfg)\n",
    "\n",
    "        _run_experiment(agent, f'{i}')\n",
    "\n",
    "def _run_acs2er_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2ER(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=ER_BUFFER_SIZE,\n",
    "            er_min_samples=ER_BUFFER_MIN_SAMPLES,\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2ER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-ER', f'{i}'))\n",
    "\n",
    "def run_acs2er_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2ER - {er_samples_number}\")\n",
    "        _run_acs2er_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2ER - {er_samples_number}\")\n",
    "\n",
    "\n",
    "def _run_acs2eer_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2EER(           \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=EER_BUFFER_SIZE,\n",
    "            er_min_samples=int(EER_BUFFER_MIN_SAMPLES),\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2EER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-EER', f'{i}'))\n",
    "\n",
    "def run_acs2eer_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2EER - {er_samples_number}\")\n",
    "        _run_acs2eer_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2EER - {er_samples_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 18, 'reward': 1000, 'perf_time': 0.0465710999999942, 'knowledge': 54.418604651162795, 'specificity': 0.7147177419354839, 'optimal': 67.24137931034483, 'optimal_reliable': 60.3448275862069, 'population': 620, 'numerosity': 620, 'reliable': 282}\n",
      "INFO:lcs.agents.Agent:{'trial': 2000, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.013290499999925487, 'knowledge': 66.04651162790698, 'specificity': 0.7212351945854484, 'optimal': 70.6896551724138, 'optimal_reliable': 68.96551724137932, 'population': 591, 'numerosity': 591, 'reliable': 334}\n",
      "INFO:lcs.agents.Agent:{'trial': 3000, 'steps_in_trial': 40, 'reward': 1000, 'perf_time': 0.09738860000004479, 'knowledge': 74.88372093023256, 'specificity': 0.7240853658536586, 'optimal': 70.6896551724138, 'optimal_reliable': 70.6896551724138, 'population': 574, 'numerosity': 574, 'reliable': 379}\n",
      "INFO:lcs.agents.Agent:{'trial': 4000, 'steps_in_trial': 16, 'reward': 1000, 'perf_time': 0.04092220000006819, 'knowledge': 78.6046511627907, 'specificity': 0.725262697022767, 'optimal': 70.6896551724138, 'optimal_reliable': 70.6896551724138, 'population': 571, 'numerosity': 571, 'reliable': 406}\n",
      "INFO:lcs.agents.Agent:{'trial': 5000, 'steps_in_trial': 16, 'reward': 1000, 'perf_time': 0.034592100000054415, 'knowledge': 83.25581395348837, 'specificity': 0.7276785714285714, 'optimal': 74.13793103448276, 'optimal_reliable': 74.13793103448276, 'population': 560, 'numerosity': 560, 'reliable': 422}\n",
      "INFO:lcs.agents.Agent:{'trial': 6000, 'steps_in_trial': 31, 'reward': 1000, 'perf_time': 0.0662096000000929, 'knowledge': 86.9767441860465, 'specificity': 0.7297727272727272, 'optimal': 74.13793103448276, 'optimal_reliable': 74.13793103448276, 'population': 550, 'numerosity': 550, 'reliable': 439}\n",
      "INFO:lcs.agents.Agent:{'trial': 7000, 'steps_in_trial': 12, 'reward': 1000, 'perf_time': 0.02503730000012183, 'knowledge': 88.83720930232558, 'specificity': 0.730540293040293, 'optimal': 75.86206896551724, 'optimal_reliable': 75.86206896551724, 'population': 546, 'numerosity': 546, 'reliable': 445}\n",
      "INFO:lcs.agents.Agent:{'trial': 8000, 'steps_in_trial': 8, 'reward': 1000, 'perf_time': 0.017259200000353303, 'knowledge': 89.76744186046511, 'specificity': 0.73046875, 'optimal': 75.86206896551724, 'optimal_reliable': 75.86206896551724, 'population': 544, 'numerosity': 544, 'reliable': 451}\n",
      "INFO:lcs.agents.Agent:{'trial': 9000, 'steps_in_trial': 27, 'reward': 1000, 'perf_time': 0.06254519999993136, 'knowledge': 92.55813953488372, 'specificity': 0.7320772058823529, 'optimal': 77.58620689655173, 'optimal_reliable': 77.58620689655173, 'population': 544, 'numerosity': 544, 'reliable': 466}\n",
      "INFO:lcs.agents.Agent:{'trial': 10000, 'steps_in_trial': 17, 'reward': 1000, 'perf_time': 0.03529969999999594, 'knowledge': 93.48837209302326, 'specificity': 0.7309633027522936, 'optimal': 79.3103448275862, 'optimal_reliable': 79.3103448275862, 'population': 545, 'numerosity': 545, 'reliable': 473}\n"
     ]
    }
   ],
   "source": [
    "run_acs2_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2ER Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2ER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 23, 'reward': 1000, 'perf_time': 0.3538936999998441, 'knowledge': 78.6046511627907, 'specificity': 0.7293595679012346, 'optimal': 79.3103448275862, 'optimal_reliable': 81.03448275862068, 'population': 648, 'numerosity': 648, 'reliable': 472}\n",
      "INFO:lcs.agents.Agent:{'trial': 2000, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.05758299999979499, 'knowledge': 93.48837209302326, 'specificity': 0.7366144975288303, 'optimal': 79.3103448275862, 'optimal_reliable': 79.3103448275862, 'population': 607, 'numerosity': 607, 'reliable': 535}\n",
      "INFO:lcs.agents.Agent:{'trial': 3000, 'steps_in_trial': 17, 'reward': 1000, 'perf_time': 0.30541649999941, 'knowledge': 95.34883720930233, 'specificity': 0.7389643463497453, 'optimal': 84.48275862068965, 'optimal_reliable': 84.48275862068965, 'population': 589, 'numerosity': 589, 'reliable': 547}\n",
      "INFO:lcs.agents.Agent:{'trial': 4000, 'steps_in_trial': 26, 'reward': 1000, 'perf_time': 0.36143019999963144, 'knowledge': 95.81395348837209, 'specificity': 0.7395299145299146, 'optimal': 87.93103448275862, 'optimal_reliable': 87.93103448275862, 'population': 585, 'numerosity': 585, 'reliable': 553}\n",
      "INFO:lcs.agents.Agent:{'trial': 5000, 'steps_in_trial': 17, 'reward': 1000, 'perf_time': 0.26146500000049855, 'knowledge': 97.20930232558139, 'specificity': 0.7401202749140894, 'optimal': 87.93103448275862, 'optimal_reliable': 87.93103448275862, 'population': 582, 'numerosity': 582, 'reliable': 561}\n",
      "INFO:lcs.agents.Agent:{'trial': 6000, 'steps_in_trial': 22, 'reward': 1000, 'perf_time': 0.31541589999960706, 'knowledge': 98.13953488372093, 'specificity': 0.7415511265164645, 'optimal': 87.93103448275862, 'optimal_reliable': 87.93103448275862, 'population': 577, 'numerosity': 577, 'reliable': 567}\n",
      "INFO:lcs.agents.Agent:{'trial': 7000, 'steps_in_trial': 31, 'reward': 1000, 'perf_time': 0.49930940000012924, 'knowledge': 98.13953488372093, 'specificity': 0.7415511265164645, 'optimal': 87.93103448275862, 'optimal_reliable': 87.93103448275862, 'population': 577, 'numerosity': 577, 'reliable': 567}\n",
      "INFO:lcs.agents.Agent:{'trial': 8000, 'steps_in_trial': 6, 'reward': 1000, 'perf_time': 0.08500999999978376, 'knowledge': 98.6046511627907, 'specificity': 0.7415511265164645, 'optimal': 87.93103448275862, 'optimal_reliable': 87.93103448275862, 'population': 577, 'numerosity': 577, 'reliable': 568}\n",
      "INFO:lcs.agents.Agent:{'trial': 9000, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.15359109999917564, 'knowledge': 99.53488372093024, 'specificity': 0.7417534722222222, 'optimal': 96.55172413793103, 'optimal_reliable': 96.55172413793103, 'population': 576, 'numerosity': 576, 'reliable': 571}\n",
      "INFO:lcs.agents.Agent:{'trial': 10000, 'steps_in_trial': 14, 'reward': 1000, 'perf_time': 0.2691494999999122, 'knowledge': 100.0, 'specificity': 0.7417247386759582, 'optimal': 96.55172413793103, 'optimal_reliable': 96.55172413793103, 'population': 574, 'numerosity': 574, 'reliable': 573}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2ER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2er_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2EER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 14, 'reward': 1000, 'perf_time': 1.4907734999997047, 'knowledge': 85.11627906976744, 'specificity': 0.7476679104477612, 'optimal': 79.3103448275862, 'optimal_reliable': 77.58620689655173, 'population': 536, 'numerosity': 536, 'reliable': 439}\n",
      "INFO:lcs.agents.Agent:{'trial': 2000, 'steps_in_trial': 16, 'reward': 1000, 'perf_time': 0.3009994000003644, 'knowledge': 92.09302325581396, 'specificity': 0.75, 'optimal': 84.48275862068965, 'optimal_reliable': 84.48275862068965, 'population': 521, 'numerosity': 521, 'reliable': 468}\n",
      "INFO:lcs.agents.Agent:{'trial': 3000, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.17036390000066604, 'knowledge': 96.27906976744185, 'specificity': 0.7531800391389433, 'optimal': 86.20689655172413, 'optimal_reliable': 86.20689655172413, 'population': 511, 'numerosity': 511, 'reliable': 483}\n",
      "INFO:lcs.agents.Agent:{'trial': 4000, 'steps_in_trial': 12, 'reward': 1000, 'perf_time': 0.1730215000006865, 'knowledge': 97.67441860465115, 'specificity': 0.7544554455445545, 'optimal': 87.93103448275862, 'optimal_reliable': 87.93103448275862, 'population': 505, 'numerosity': 505, 'reliable': 488}\n",
      "INFO:lcs.agents.Agent:{'trial': 5000, 'steps_in_trial': 10, 'reward': 1000, 'perf_time': 0.1905131999992591, 'knowledge': 98.13953488372093, 'specificity': 0.7544554455445545, 'optimal': 89.65517241379311, 'optimal_reliable': 89.65517241379311, 'population': 505, 'numerosity': 505, 'reliable': 490}\n",
      "INFO:lcs.agents.Agent:{'trial': 6000, 'steps_in_trial': 1, 'reward': 1000, 'perf_time': 0.22341009999945527, 'knowledge': 98.6046511627907, 'specificity': 0.7552290836653387, 'optimal': 89.65517241379311, 'optimal_reliable': 89.65517241379311, 'population': 502, 'numerosity': 502, 'reliable': 491}\n",
      "INFO:lcs.agents.Agent:{'trial': 7000, 'steps_in_trial': 23, 'reward': 1000, 'perf_time': 0.21973369999977876, 'knowledge': 99.53488372093024, 'specificity': 0.7549900199600799, 'optimal': 89.65517241379311, 'optimal_reliable': 89.65517241379311, 'population': 501, 'numerosity': 501, 'reliable': 493}\n",
      "INFO:lcs.agents.Agent:{'trial': 8000, 'steps_in_trial': 13, 'reward': 1000, 'perf_time': 0.18904029999976046, 'knowledge': 99.53488372093024, 'specificity': 0.75625, 'optimal': 91.37931034482759, 'optimal_reliable': 91.37931034482759, 'population': 500, 'numerosity': 500, 'reliable': 493}\n",
      "INFO:lcs.agents.Agent:{'trial': 9000, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.20946230000117794, 'knowledge': 99.53488372093024, 'specificity': 0.7565261044176707, 'optimal': 91.37931034482759, 'optimal_reliable': 91.37931034482759, 'population': 498, 'numerosity': 498, 'reliable': 493}\n",
      "INFO:lcs.agents.Agent:{'trial': 10000, 'steps_in_trial': 17, 'reward': 1000, 'perf_time': 0.3633767999999691, 'knowledge': 100.0, 'specificity': 0.7567907444668008, 'optimal': 94.82758620689656, 'optimal_reliable': 94.82758620689656, 'population': 497, 'numerosity': 497, 'reliable': 494}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2EER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2eer_experiments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec208294d083f15f7ed14d725810d00783612c76b14ab5c82bea0e3fdbc09b32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
