{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from utils.run_utils import Runner\n",
    "\n",
    "import gym\n",
    "import gym_maze\n",
    "\n",
    "from lcs.agents import Agent\n",
    "from lcs.agents.acs2 import ACS2, Configuration as CFG_ACS2, ClassifiersList\n",
    "from lcs.agents.acs2er import ACS2ER, Configuration as CFG_ACS2ER, ReplayMemory, ReplayMemorySample\n",
    "from lcs.agents.acs2eer import ACS2EER, Configuration as CFG_ACS2EER, TrialReplayMemory\n",
    "from lcs.metrics import population_metrics\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = \"MazeF2-v0\" \n",
    "EXPLORE_EXPLOIT_TRIALS = 10000\n",
    "\n",
    "# The size of ER replay memory buffer\n",
    "ER_BUFFER_SIZE = 10000\n",
    "# The minimum number of samples of ER replay memory buffer to start replying samples (warm-up phase)\n",
    "ER_BUFFER_MIN_SAMPLES = 1000\n",
    "# The number of samples to be replayed druing ER phase\n",
    "ER_SAMPLES_NUMBER_LIST = [3]\n",
    "\n",
    "EER_BUFFER_SIZE = 1000\n",
    "EER_BUFFER_MIN_SAMPLES = 25\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "REPEAT_START = 1\n",
    "REPEAT = 10\n",
    "\n",
    "EXPERIMENT_NAME = \"MAZE_F2_EXP_1\" # Please edit if running new experiment to do not override saved results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner('MAZE', EXPERIMENT_NAME, MAZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE_PATH = 0\n",
    "MAZE_REWARD = 9\n",
    "\n",
    "optimal_paths_env = gym.make(MAZE)\n",
    "matrix = optimal_paths_env.matrix\n",
    "X = matrix.shape[1]\n",
    "Y = matrix.shape[0]\n",
    "\n",
    "def get_reward_pos():\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            if(matrix[i, j] == MAZE_REWARD):\n",
    "                return(i, j)\n",
    "\n",
    "def get_possible_neighbour_cords(pos_y, pos_x):\n",
    "    n = ((pos_y - 1, pos_x), 4)\n",
    "    ne = ((pos_y - 1, pos_x + 1), 5)\n",
    "    e = ((pos_y, pos_x + 1), 6)\n",
    "    se = ((pos_y + 1, pos_x + 1), 7)\n",
    "    s = ((pos_y + 1, pos_x), 0)\n",
    "    sw = ((pos_y + 1, pos_x - 1), 1)\n",
    "    w = ((pos_y, pos_x - 1), 2)\n",
    "    nw = ((pos_y - 1, pos_x - 1), 3)\n",
    "\n",
    "    return [n, ne, e, se, s, sw, w, nw]\n",
    "\n",
    "    \n",
    "optimal_actions = []\n",
    "\n",
    "root_node = get_reward_pos()\n",
    "\n",
    "def is_included(cords, level):\n",
    "    return any(op_cords[0] == cords[0] and op_cords[1] == cords[1] and level != op_level for op_cords, _, op_level in optimal_actions)\n",
    "\n",
    "\n",
    "def get_optimal_actions_to(node, level):\n",
    "    neighbour_cords = get_possible_neighbour_cords(node[0], node[1])\n",
    "\n",
    "    next_level_cords = []\n",
    "    for (pos_y, pos_x), action in neighbour_cords:\n",
    "        if (not is_included((pos_y, pos_x), level)) and matrix[pos_y, pos_x] == MAZE_PATH:\n",
    "            optimal_actions.append(((pos_y, pos_x), action, level))\n",
    "            next_level_cords.append((pos_y, pos_x))\n",
    "\n",
    "    return next_level_cords\n",
    "\n",
    "LEVEL = 0\n",
    "next_level_cords = get_optimal_actions_to(root_node, LEVEL)\n",
    "\n",
    "while len(next_level_cords) > 0:\n",
    "    LEVEL += 1\n",
    "    new_next_level_cords = []\n",
    "    for nlc in next_level_cords:\n",
    "        new_next_level_cords += get_optimal_actions_to(nlc, LEVEL)\n",
    "\n",
    "    next_level_cords = new_next_level_cords\n",
    "\n",
    "positions_actions = defaultdict(set)\n",
    "for cords, a, _ in optimal_actions: positions_actions[cords].add(a)\n",
    "\n",
    "positions_actions = positions_actions.items()\n",
    "POSITIONS_OPTIMAL_ACTIONS = list(map(lambda pa: (optimal_paths_env.env.maze.perception(pa[0]), list(pa[1])), positions_actions))\n",
    "POSITIONS_OPTIMAL_ACTIONS_LENGTH = len(POSITIONS_OPTIMAL_ACTIONS)\n",
    "\n",
    "\n",
    "\n",
    "def _maze_optimal(classifiers) -> float:\n",
    "    nr_correct = 0\n",
    "\n",
    "    for p0, optimal_actions_list in POSITIONS_OPTIMAL_ACTIONS:\n",
    "        match_set = classifiers.form_match_set(p0)\n",
    "        cl = match_set.get_best_classifier()\n",
    "\n",
    "        if cl is not None and optimal_actions_list.count(cl.action) > 0:\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / POSITIONS_OPTIMAL_ACTIONS_LENGTH * 100.0\n",
    "\n",
    "\n",
    "def _maze_optimal_reliable(classifiers) -> float:\n",
    "    return _maze_optimal(ClassifiersList(*[c for c in classifiers if c.is_reliable()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_transitions():\n",
    "    knowledge_env = gym.make(MAZE)\n",
    "    transitions = knowledge_env.env.get_transitions()\n",
    "    transitions = list(map(lambda t: [knowledge_env.env.maze.perception(t[0]), t[1], knowledge_env.env.maze.perception(t[2])], transitions))\n",
    "\n",
    "    return transitions\n",
    "\n",
    "TRANSITIONS = _get_transitions()\n",
    "TRANSITIONS_LENGTH = len(TRANSITIONS)\n",
    "\n",
    "def _maze_knowledge(population) -> float:\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for p0, action, p1 in TRANSITIONS:\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / TRANSITIONS_LENGTH * 100.0\n",
    "\n",
    "def _maze_specificity(population) -> float:\n",
    "    pop_len = len(population)\n",
    "    if(pop_len) == 0:\n",
    "        return 0\n",
    "    return sum(map(lambda c: c.specificity, population)) / pop_len\n",
    "\n",
    "def _maze_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': _maze_knowledge(pop),\n",
    "        \"specificity\": _maze_specificity(agent.population),\n",
    "        \"optimal\": _maze_optimal(agent.population),\n",
    "        \"optimal_reliable\": _maze_optimal_reliable(agent.population)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_experiment(agent, path):\n",
    "    runner.run_experiment_explore_exploit(agent, gym.make(MAZE), EXPLORE_EXPLOIT_TRIALS, path)\n",
    "\n",
    "def run_acs2_experiment():\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2(cfg)\n",
    "\n",
    "        _run_experiment(agent, f'{i}')\n",
    "\n",
    "def _run_acs2er_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2ER(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=ER_BUFFER_SIZE,\n",
    "            er_min_samples=ER_BUFFER_MIN_SAMPLES,\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2ER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-ER', f'{i}'))\n",
    "\n",
    "def run_acs2er_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2ER - {er_samples_number}\")\n",
    "        _run_acs2er_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2ER - {er_samples_number}\")\n",
    "\n",
    "\n",
    "def _run_acs2eer_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2EER(           \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=EER_BUFFER_SIZE,\n",
    "            er_min_samples=int(EER_BUFFER_MIN_SAMPLES),\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2EER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-EER', f'{i}'))\n",
    "\n",
    "def run_acs2eer_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2EER - {er_samples_number}\")\n",
    "        _run_acs2eer_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2EER - {er_samples_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 100, 'steps_in_trial': 9, 'reward': 1000, 'perf_time': 0.009275499999999326, 'knowledge': 41.17647058823529, 'specificity': 0.2606707317073171, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 82, 'numerosity': 82, 'reliable': 13}\n",
      "INFO:lcs.agents.Agent:{'trial': 200, 'steps_in_trial': 8, 'reward': 1000, 'perf_time': 0.008363400000000354, 'knowledge': 47.05882352941176, 'specificity': 0.25892857142857145, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 84, 'numerosity': 84, 'reliable': 23}\n",
      "INFO:lcs.agents.Agent:{'trial': 300, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.00241340000000001, 'knowledge': 82.35294117647058, 'specificity': 0.26676829268292684, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 82, 'numerosity': 82, 'reliable': 42}\n",
      "INFO:lcs.agents.Agent:{'trial': 400, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.003773799999999383, 'knowledge': 88.23529411764706, 'specificity': 0.26676829268292684, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 82, 'numerosity': 82, 'reliable': 54}\n",
      "INFO:lcs.agents.Agent:{'trial': 500, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.0033919999999998396, 'knowledge': 88.23529411764706, 'specificity': 0.26676829268292684, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 82, 'numerosity': 82, 'reliable': 58}\n",
      "INFO:lcs.agents.Agent:{'trial': 600, 'steps_in_trial': 11, 'reward': 1000, 'perf_time': 0.009499899999999784, 'knowledge': 88.23529411764706, 'specificity': 0.2700617283950617, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 81, 'numerosity': 81, 'reliable': 62}\n",
      "INFO:lcs.agents.Agent:{'trial': 700, 'steps_in_trial': 13, 'reward': 1000, 'perf_time': 0.012745500000001186, 'knowledge': 88.23529411764706, 'specificity': 0.2700617283950617, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 81, 'numerosity': 81, 'reliable': 63}\n",
      "INFO:lcs.agents.Agent:{'trial': 800, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.0055821999999992045, 'knowledge': 94.11764705882352, 'specificity': 0.2700617283950617, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 81, 'numerosity': 81, 'reliable': 66}\n",
      "INFO:lcs.agents.Agent:{'trial': 900, 'steps_in_trial': 10, 'reward': 1000, 'perf_time': 0.012271499999997104, 'knowledge': 94.11764705882352, 'specificity': 0.2700617283950617, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 81, 'numerosity': 81, 'reliable': 68}\n",
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 15, 'reward': 1000, 'perf_time': 0.013084500000001498, 'knowledge': 94.11764705882352, 'specificity': 0.2689873417721519, 'optimal': 66.66666666666666, 'optimal_reliable': 66.66666666666666, 'population': 79, 'numerosity': 79, 'reliable': 72}\n"
     ]
    }
   ],
   "source": [
    "run_acs2_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2ER Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2ER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 100, 'steps_in_trial': 11, 'reward': 1000, 'perf_time': 0.06721920000000026, 'knowledge': 29.411764705882355, 'specificity': 0.24849397590361447, 'optimal': 83.33333333333334, 'optimal_reliable': 50.0, 'population': 83, 'numerosity': 83, 'reliable': 26}\n",
      "INFO:lcs.agents.Agent:{'trial': 200, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.03306390000000192, 'knowledge': 76.47058823529412, 'specificity': 0.26080246913580246, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 81, 'numerosity': 81, 'reliable': 53}\n",
      "INFO:lcs.agents.Agent:{'trial': 300, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.015124000000000137, 'knowledge': 100.0, 'specificity': 0.25811688311688313, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 77, 'numerosity': 77, 'reliable': 66}\n",
      "INFO:lcs.agents.Agent:{'trial': 400, 'steps_in_trial': 9, 'reward': 1000, 'perf_time': 0.028613299999999953, 'knowledge': 100.0, 'specificity': 0.25316455696202533, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 79, 'numerosity': 79, 'reliable': 72}\n",
      "INFO:lcs.agents.Agent:{'trial': 500, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.014579200000000014, 'knowledge': 100.0, 'specificity': 0.2565789473684211, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 76, 'numerosity': 76, 'reliable': 74}\n",
      "INFO:lcs.agents.Agent:{'trial': 600, 'steps_in_trial': 12, 'reward': 1000, 'perf_time': 0.04173749999999998, 'knowledge': 100.0, 'specificity': 0.2565789473684211, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 76, 'numerosity': 76, 'reliable': 74}\n",
      "INFO:lcs.agents.Agent:{'trial': 700, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.008102300000004448, 'knowledge': 100.0, 'specificity': 0.2565789473684211, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 76, 'numerosity': 76, 'reliable': 75}\n",
      "INFO:lcs.agents.Agent:{'trial': 800, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.02415290000000425, 'knowledge': 100.0, 'specificity': 0.255, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 75, 'numerosity': 75, 'reliable': 75}\n",
      "INFO:lcs.agents.Agent:{'trial': 900, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.018826900000000535, 'knowledge': 100.0, 'specificity': 0.255, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 75, 'numerosity': 75, 'reliable': 75}\n",
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 1, 'reward': 1000, 'perf_time': 0.0032159999999947786, 'knowledge': 100.0, 'specificity': 0.255, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 75, 'numerosity': 75, 'reliable': 75}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2ER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2er_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2EER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 100, 'steps_in_trial': 8, 'reward': 1000, 'perf_time': 0.11431710000000095, 'knowledge': 100.0, 'specificity': 0.2604166666666667, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 84, 'numerosity': 84, 'reliable': 80}\n",
      "INFO:lcs.agents.Agent:{'trial': 200, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.14471409999999452, 'knowledge': 100.0, 'specificity': 0.25903614457831325, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 83, 'numerosity': 83, 'reliable': 81}\n",
      "INFO:lcs.agents.Agent:{'trial': 300, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.02148369999999744, 'knowledge': 100.0, 'specificity': 0.25588235294117645, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 85, 'numerosity': 85, 'reliable': 82}\n",
      "INFO:lcs.agents.Agent:{'trial': 400, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.013485500000001593, 'knowledge': 100.0, 'specificity': 0.25588235294117645, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 85, 'numerosity': 85, 'reliable': 83}\n",
      "INFO:lcs.agents.Agent:{'trial': 500, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.012890500000004579, 'knowledge': 100.0, 'specificity': 0.25744047619047616, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 84, 'numerosity': 84, 'reliable': 83}\n",
      "INFO:lcs.agents.Agent:{'trial': 600, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.07214890000000196, 'knowledge': 100.0, 'specificity': 0.25744047619047616, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 84, 'numerosity': 84, 'reliable': 83}\n",
      "INFO:lcs.agents.Agent:{'trial': 700, 'steps_in_trial': 15, 'reward': 1000, 'perf_time': 0.017307899999991605, 'knowledge': 100.0, 'specificity': 0.25744047619047616, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 84, 'numerosity': 84, 'reliable': 83}\n",
      "INFO:lcs.agents.Agent:{'trial': 800, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.01919729999998765, 'knowledge': 100.0, 'specificity': 0.25744047619047616, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 84, 'numerosity': 84, 'reliable': 83}\n",
      "INFO:lcs.agents.Agent:{'trial': 900, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.0222061999999994, 'knowledge': 100.0, 'specificity': 0.2560240963855422, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 83, 'numerosity': 83, 'reliable': 83}\n",
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.01901050000000737, 'knowledge': 100.0, 'specificity': 0.2560240963855422, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 83, 'numerosity': 83, 'reliable': 83}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2EER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2eer_experiments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec208294d083f15f7ed14d725810d00783612c76b14ab5c82bea0e3fdbc09b32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
