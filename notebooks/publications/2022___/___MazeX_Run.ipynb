{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from utils.run_utils import Runner\n",
    "\n",
    "import gym\n",
    "import gym_maze\n",
    "\n",
    "from lcs.agents import Agent\n",
    "from lcs.agents.acs2 import ACS2, Configuration as CFG_ACS2, ClassifiersList\n",
    "from lcs.agents.acs2er import ACS2ER, Configuration as CFG_ACS2ER, ReplayMemory, ReplayMemorySample\n",
    "from lcs.agents.acs2eer import ACS2EER, Configuration as CFG_ACS2EER, TrialReplayMemory\n",
    "from lcs.metrics import population_metrics\n",
    "\n",
    "# Logger\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE = \"MazeX-v0\" \n",
    "EXPLORE_EXPLOIT_TRIALS = 10000\n",
    "\n",
    "# The size of ER replay memory buffer\n",
    "ER_BUFFER_SIZE = 10000\n",
    "# The minimum number of samples of ER replay memory buffer to start replying samples (warm-up phase)\n",
    "ER_BUFFER_MIN_SAMPLES = 1000\n",
    "# The number of samples to be replayed druing ER phase\n",
    "ER_SAMPLES_NUMBER_LIST = [3]\n",
    "\n",
    "EER_BUFFER_SIZE = 1000\n",
    "EER_BUFFER_MIN_SAMPLES = 25\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "REPEAT_START = 1\n",
    "REPEAT = 1\n",
    "\n",
    "EXPERIMENT_NAME = \"MAZE_X_EXP_2\" # Please edit if running new experiment to do not override saved results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner('MAZE', EXPERIMENT_NAME, MAZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAZE_PATH = 0\n",
    "MAZE_REWARD = 9\n",
    "\n",
    "optimal_paths_env = gym.make(MAZE)\n",
    "matrix = optimal_paths_env.matrix\n",
    "X = matrix.shape[1]\n",
    "Y = matrix.shape[0]\n",
    "\n",
    "def get_reward_pos():\n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            if(matrix[i, j] == MAZE_REWARD):\n",
    "                return(i, j)\n",
    "\n",
    "def get_possible_neighbour_cords(pos_y, pos_x):\n",
    "    n = ((pos_y - 1, pos_x), 4)\n",
    "    ne = ((pos_y - 1, pos_x + 1), 5)\n",
    "    e = ((pos_y, pos_x + 1), 6)\n",
    "    se = ((pos_y + 1, pos_x + 1), 7)\n",
    "    s = ((pos_y + 1, pos_x), 0)\n",
    "    sw = ((pos_y + 1, pos_x - 1), 1)\n",
    "    w = ((pos_y, pos_x - 1), 2)\n",
    "    nw = ((pos_y - 1, pos_x - 1), 3)\n",
    "\n",
    "    return [n, ne, e, se, s, sw, w, nw]\n",
    "\n",
    "    \n",
    "optimal_actions = []\n",
    "\n",
    "root_node = get_reward_pos()\n",
    "\n",
    "def is_included(cords, level):\n",
    "    return any(op_cords[0] == cords[0] and op_cords[1] == cords[1] and level != op_level for op_cords, _, op_level in optimal_actions)\n",
    "\n",
    "\n",
    "def get_optimal_actions_to(node, level):\n",
    "    neighbour_cords = get_possible_neighbour_cords(node[0], node[1])\n",
    "\n",
    "    next_level_cords = []\n",
    "    for (pos_y, pos_x), action in neighbour_cords:\n",
    "        if (not is_included((pos_y, pos_x), level)) and matrix[pos_y, pos_x] == MAZE_PATH:\n",
    "            optimal_actions.append(((pos_y, pos_x), action, level))\n",
    "            next_level_cords.append((pos_y, pos_x))\n",
    "\n",
    "    return next_level_cords\n",
    "\n",
    "LEVEL = 0\n",
    "next_level_cords = get_optimal_actions_to(root_node, LEVEL)\n",
    "\n",
    "while len(next_level_cords) > 0:\n",
    "    LEVEL += 1\n",
    "    new_next_level_cords = []\n",
    "    for nlc in next_level_cords:\n",
    "        new_next_level_cords += get_optimal_actions_to(nlc, LEVEL)\n",
    "\n",
    "    next_level_cords = new_next_level_cords\n",
    "\n",
    "positions_actions = defaultdict(set)\n",
    "for cords, a, _ in optimal_actions: positions_actions[cords].add(a)\n",
    "\n",
    "positions_actions = positions_actions.items()\n",
    "POSITIONS_OPTIMAL_ACTIONS = list(map(lambda pa: (optimal_paths_env.env.maze.perception(pa[0]), list(pa[1])), positions_actions))\n",
    "POSITIONS_OPTIMAL_ACTIONS_LENGTH = len(POSITIONS_OPTIMAL_ACTIONS)\n",
    "\n",
    "\n",
    "\n",
    "def _maze_optimal(classifiers) -> float:\n",
    "    nr_correct = 0\n",
    "\n",
    "    for p0, optimal_actions_list in POSITIONS_OPTIMAL_ACTIONS:\n",
    "        match_set = classifiers.form_match_set(p0)\n",
    "        cl = match_set.get_best_classifier()\n",
    "\n",
    "        if cl is not None and optimal_actions_list.count(cl.action) > 0:\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / POSITIONS_OPTIMAL_ACTIONS_LENGTH * 100.0\n",
    "\n",
    "\n",
    "def _maze_optimal_reliable(classifiers) -> float:\n",
    "    return _maze_optimal(ClassifiersList(*[c for c in classifiers if c.is_reliable()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_transitions():\n",
    "    knowledge_env = gym.make(MAZE)\n",
    "    transitions = knowledge_env.env.get_transitions()\n",
    "    transitions = list(map(lambda t: [knowledge_env.env.maze.perception(t[0]), t[1], knowledge_env.env.maze.perception(t[2])], transitions))\n",
    "\n",
    "    return transitions\n",
    "\n",
    "TRANSITIONS = _get_transitions()\n",
    "TRANSITIONS_LENGTH = len(TRANSITIONS)\n",
    "\n",
    "def _maze_knowledge(population) -> float:\n",
    "    # Take into consideration only reliable classifiers\n",
    "    reliable_classifiers = [c for c in population if c.is_reliable()]\n",
    "\n",
    "    # Count how many transitions are anticipated correctly\n",
    "    nr_correct = 0\n",
    "\n",
    "    # For all possible destinations from each path cell\n",
    "    for p0, action, p1 in TRANSITIONS:\n",
    "        if any([True for cl in reliable_classifiers\n",
    "                if cl.predicts_successfully(p0, action, p1)]):\n",
    "            nr_correct += 1\n",
    "\n",
    "    return nr_correct / TRANSITIONS_LENGTH * 100.0\n",
    "\n",
    "def _maze_specificity(population) -> float:\n",
    "    pop_len = len(population)\n",
    "    if(pop_len) == 0:\n",
    "        return 0\n",
    "    return sum(map(lambda c: c.specificity, population)) / pop_len\n",
    "\n",
    "def _maze_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': _maze_knowledge(pop),\n",
    "        \"specificity\": _maze_specificity(agent.population),\n",
    "        \"optimal\": _maze_optimal(agent.population),\n",
    "        \"optimal_reliable\": _maze_optimal_reliable(agent.population)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_experiment(agent, path):\n",
    "    runner.run_experiment_explore_exploit(agent, gym.make(MAZE), EXPLORE_EXPLOIT_TRIALS, path)\n",
    "\n",
    "def run_acs2_experiment():\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2(cfg)\n",
    "\n",
    "        _run_experiment(agent, f'{i}')\n",
    "\n",
    "def _run_acs2er_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2ER(    \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=ER_BUFFER_SIZE,\n",
    "            er_min_samples=ER_BUFFER_MIN_SAMPLES,\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2ER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-ER', f'{i}'))\n",
    "\n",
    "def run_acs2er_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2ER - {er_samples_number}\")\n",
    "        _run_acs2er_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2ER - {er_samples_number}\")\n",
    "\n",
    "\n",
    "def _run_acs2eer_experiment(er_samples_number: int):\n",
    "    for i in range(REPEAT_START, REPEAT_START + REPEAT):\n",
    "        # Create agent \n",
    "        cfg = CFG_ACS2EER(           \n",
    "            classifier_length=8,\n",
    "            number_of_possible_actions=8,\n",
    "            metrics_trial_frequency=1,\n",
    "            er_buffer_size=EER_BUFFER_SIZE,\n",
    "            er_min_samples=int(EER_BUFFER_MIN_SAMPLES),\n",
    "            er_samples_number=er_samples_number,\n",
    "            user_metrics_collector_fcn=_maze_metrics)\n",
    "        agent = ACS2EER(cfg)\n",
    "\n",
    "        _run_experiment(agent, os.path.join(f'm_3-EER', f'{i}'))\n",
    "\n",
    "def run_acs2eer_experiments():\n",
    "    for er_samples_number in ER_SAMPLES_NUMBER_LIST:\n",
    "        print(f\"START - ACS2EER - {er_samples_number}\")\n",
    "        _run_acs2eer_experiment(er_samples_number)\n",
    "        print(f\"END - ACS2EER - {er_samples_number}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2 Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.008754200000112178, 'knowledge': 44.1025641025641, 'specificity': 0.6976439790575916, 'optimal': 78.84615384615384, 'optimal_reliable': 67.3076923076923, 'population': 573, 'numerosity': 573, 'reliable': 220}\n",
      "INFO:lcs.agents.Agent:{'trial': 2000, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.017613499999242777, 'knowledge': 55.38461538461539, 'specificity': 0.7077981651376147, 'optimal': 78.84615384615384, 'optimal_reliable': 78.84615384615384, 'population': 545, 'numerosity': 545, 'reliable': 261}\n",
      "INFO:lcs.agents.Agent:{'trial': 3000, 'steps_in_trial': 14, 'reward': 1000, 'perf_time': 0.028798600000300212, 'knowledge': 65.12820512820512, 'specificity': 0.7149621212121212, 'optimal': 78.84615384615384, 'optimal_reliable': 78.84615384615384, 'population': 528, 'numerosity': 528, 'reliable': 294}\n",
      "INFO:lcs.agents.Agent:{'trial': 4000, 'steps_in_trial': 21, 'reward': 1000, 'perf_time': 0.04901750000044558, 'knowledge': 75.38461538461539, 'specificity': 0.7189922480620154, 'optimal': 78.84615384615384, 'optimal_reliable': 78.84615384615384, 'population': 516, 'numerosity': 516, 'reliable': 330}\n",
      "INFO:lcs.agents.Agent:{'trial': 5000, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.005589999999756401, 'knowledge': 78.97435897435898, 'specificity': 0.7215909090909091, 'optimal': 78.84615384615384, 'optimal_reliable': 78.84615384615384, 'population': 506, 'numerosity': 506, 'reliable': 350}\n",
      "INFO:lcs.agents.Agent:{'trial': 6000, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.017706100000395963, 'knowledge': 83.58974358974359, 'specificity': 0.7242424242424242, 'optimal': 78.84615384615384, 'optimal_reliable': 78.84615384615384, 'population': 495, 'numerosity': 495, 'reliable': 372}\n",
      "INFO:lcs.agents.Agent:{'trial': 7000, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.00347550000060437, 'knowledge': 85.64102564102564, 'specificity': 0.7261904761904762, 'optimal': 80.76923076923077, 'optimal_reliable': 80.76923076923077, 'population': 483, 'numerosity': 483, 'reliable': 384}\n",
      "INFO:lcs.agents.Agent:{'trial': 8000, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.005923099999563419, 'knowledge': 88.71794871794872, 'specificity': 0.7267259414225942, 'optimal': 80.76923076923077, 'optimal_reliable': 80.76923076923077, 'population': 478, 'numerosity': 478, 'reliable': 393}\n",
      "INFO:lcs.agents.Agent:{'trial': 9000, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.0037472000003617723, 'knowledge': 90.76923076923077, 'specificity': 0.7278012684989429, 'optimal': 80.76923076923077, 'optimal_reliable': 80.76923076923077, 'population': 473, 'numerosity': 473, 'reliable': 407}\n",
      "INFO:lcs.agents.Agent:{'trial': 10000, 'steps_in_trial': 10, 'reward': 1000, 'perf_time': 0.017714699999487493, 'knowledge': 94.87179487179486, 'specificity': 0.7271276595744681, 'optimal': 80.76923076923077, 'optimal_reliable': 80.76923076923077, 'population': 470, 'numerosity': 470, 'reliable': 417}\n"
     ]
    }
   ],
   "source": [
    "run_acs2_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN ACS2ER Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2ER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.02308820000052947, 'knowledge': 75.38461538461539, 'specificity': 0.7152196652719666, 'optimal': 80.76923076923077, 'optimal_reliable': 76.92307692307693, 'population': 478, 'numerosity': 478, 'reliable': 310}\n",
      "INFO:lcs.agents.Agent:{'trial': 2000, 'steps_in_trial': 9, 'reward': 1000, 'perf_time': 0.09160669999982929, 'knowledge': 94.87179487179486, 'specificity': 0.7208710407239819, 'optimal': 78.84615384615384, 'optimal_reliable': 78.84615384615384, 'population': 442, 'numerosity': 442, 'reliable': 387}\n",
      "INFO:lcs.agents.Agent:{'trial': 3000, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.047163999999611406, 'knowledge': 97.94871794871794, 'specificity': 0.7218023255813953, 'optimal': 80.76923076923077, 'optimal_reliable': 80.76923076923077, 'population': 430, 'numerosity': 430, 'reliable': 403}\n",
      "INFO:lcs.agents.Agent:{'trial': 4000, 'steps_in_trial': 5, 'reward': 1000, 'perf_time': 0.04744919999939157, 'knowledge': 98.46153846153847, 'specificity': 0.7221244131455399, 'optimal': 82.6923076923077, 'optimal_reliable': 82.6923076923077, 'population': 426, 'numerosity': 426, 'reliable': 405}\n",
      "INFO:lcs.agents.Agent:{'trial': 5000, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.03961200000048848, 'knowledge': 100.0, 'specificity': 0.7227488151658767, 'optimal': 84.61538461538461, 'optimal_reliable': 84.61538461538461, 'population': 422, 'numerosity': 422, 'reliable': 410}\n",
      "INFO:lcs.agents.Agent:{'trial': 6000, 'steps_in_trial': 11, 'reward': 1000, 'perf_time': 0.10304069999983767, 'knowledge': 100.0, 'specificity': 0.7245203836930456, 'optimal': 88.46153846153845, 'optimal_reliable': 88.46153846153845, 'population': 417, 'numerosity': 417, 'reliable': 411}\n",
      "INFO:lcs.agents.Agent:{'trial': 7000, 'steps_in_trial': 21, 'reward': 1000, 'perf_time': 0.20176059999903373, 'knowledge': 100.0, 'specificity': 0.725, 'optimal': 88.46153846153845, 'optimal_reliable': 88.46153846153845, 'population': 415, 'numerosity': 415, 'reliable': 411}\n",
      "INFO:lcs.agents.Agent:{'trial': 8000, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.06663699999990058, 'knowledge': 100.0, 'specificity': 0.725, 'optimal': 92.3076923076923, 'optimal_reliable': 92.3076923076923, 'population': 415, 'numerosity': 415, 'reliable': 411}\n",
      "INFO:lcs.agents.Agent:{'trial': 9000, 'steps_in_trial': 26, 'reward': 1000, 'perf_time': 0.23755209999944782, 'knowledge': 100.0, 'specificity': 0.725181598062954, 'optimal': 94.23076923076923, 'optimal_reliable': 94.23076923076923, 'population': 413, 'numerosity': 413, 'reliable': 412}\n",
      "INFO:lcs.agents.Agent:{'trial': 10000, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.019390100000237, 'knowledge': 100.0, 'specificity': 0.725181598062954, 'optimal': 94.23076923076923, 'optimal_reliable': 94.23076923076923, 'population': 413, 'numerosity': 413, 'reliable': 412}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2ER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2er_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START - ACS2EER - 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lcs.agents.Agent:{'trial': 1000, 'steps_in_trial': 1, 'reward': 1000, 'perf_time': 0.08539850000124716, 'knowledge': 83.07692307692308, 'specificity': 0.725922131147541, 'optimal': 86.53846153846155, 'optimal_reliable': 86.53846153846155, 'population': 488, 'numerosity': 488, 'reliable': 377}\n",
      "INFO:lcs.agents.Agent:{'trial': 2000, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.08687880000070436, 'knowledge': 95.8974358974359, 'specificity': 0.730561555075594, 'optimal': 86.53846153846155, 'optimal_reliable': 86.53846153846155, 'population': 463, 'numerosity': 463, 'reliable': 436}\n",
      "INFO:lcs.agents.Agent:{'trial': 3000, 'steps_in_trial': 15, 'reward': 1000, 'perf_time': 0.0746424000008119, 'knowledge': 97.94871794871794, 'specificity': 0.7314814814814815, 'optimal': 92.3076923076923, 'optimal_reliable': 92.3076923076923, 'population': 459, 'numerosity': 459, 'reliable': 444}\n",
      "INFO:lcs.agents.Agent:{'trial': 4000, 'steps_in_trial': 11, 'reward': 1000, 'perf_time': 0.05771939999976894, 'knowledge': 98.46153846153847, 'specificity': 0.7315618221258134, 'optimal': 92.3076923076923, 'optimal_reliable': 92.3076923076923, 'population': 461, 'numerosity': 461, 'reliable': 446}\n",
      "INFO:lcs.agents.Agent:{'trial': 5000, 'steps_in_trial': 4, 'reward': 1000, 'perf_time': 0.06086640000103216, 'knowledge': 98.97435897435898, 'specificity': 0.7315618221258134, 'optimal': 92.3076923076923, 'optimal_reliable': 92.3076923076923, 'population': 461, 'numerosity': 461, 'reliable': 447}\n",
      "INFO:lcs.agents.Agent:{'trial': 6000, 'steps_in_trial': 7, 'reward': 1000, 'perf_time': 0.07456939999974566, 'knowledge': 99.48717948717949, 'specificity': 0.7315618221258134, 'optimal': 92.3076923076923, 'optimal_reliable': 92.3076923076923, 'population': 461, 'numerosity': 461, 'reliable': 449}\n",
      "INFO:lcs.agents.Agent:{'trial': 7000, 'steps_in_trial': 2, 'reward': 1000, 'perf_time': 0.04645920000075421, 'knowledge': 100.0, 'specificity': 0.7327680525164114, 'optimal': 92.3076923076923, 'optimal_reliable': 92.3076923076923, 'population': 457, 'numerosity': 457, 'reliable': 451}\n",
      "INFO:lcs.agents.Agent:{'trial': 8000, 'steps_in_trial': 9, 'reward': 1000, 'perf_time': 0.06114330000127666, 'knowledge': 100.0, 'specificity': 0.7328918322295805, 'optimal': 98.07692307692307, 'optimal_reliable': 98.07692307692307, 'population': 453, 'numerosity': 453, 'reliable': 451}\n",
      "INFO:lcs.agents.Agent:{'trial': 9000, 'steps_in_trial': 6, 'reward': 1000, 'perf_time': 0.09627149999869289, 'knowledge': 100.0, 'specificity': 0.7328918322295805, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 453, 'numerosity': 453, 'reliable': 451}\n",
      "INFO:lcs.agents.Agent:{'trial': 10000, 'steps_in_trial': 3, 'reward': 1000, 'perf_time': 0.06255620000047202, 'knowledge': 100.0, 'specificity': 0.7331305309734514, 'optimal': 100.0, 'optimal_reliable': 100.0, 'population': 452, 'numerosity': 452, 'reliable': 451}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END - ACS2EER - 3\n"
     ]
    }
   ],
   "source": [
    "run_acs2eer_experiments()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec208294d083f15f7ed14d725810d00783612c76b14ab5c82bea0e3fdbc09b32"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
