{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Woods1 and ACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lcs.metrics import population_metrics\n",
    "from lcs.agents import EnvironmentAdapter\n",
    "\n",
    "\n",
    "\n",
    "def common_metrics(agent, env):\n",
    "    metrics = {}\n",
    "\n",
    "    pop = agent.get_population()\n",
    "    agent_name = agent.__class__.__name__\n",
    "\n",
    "    if hasattr(agent, 'rho'):\n",
    "        metrics['rho'] = agent.rho\n",
    "        agent_name += \"_v\" + agent.cfg.rho_update_version\n",
    "    else:\n",
    "        metrics['rho'] = 0\n",
    "\n",
    "    metrics['agent'] = agent_name\n",
    "    metrics['reliable'] = len([cl for cl in pop if cl.is_reliable()])\n",
    "\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Woods1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_corridor\n",
    "import gym_woods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Woods1-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m\n",
      "\u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[33m$\u001b[0m \u001b[37m□\u001b[0m\n",
      "\u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m\n",
      "\u001b[37m□\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[30m■\u001b[0m \u001b[37m□\u001b[0m\n",
      "\u001b[37m□\u001b[0m \u001b[37m□\u001b[0m \u001b[36mX\u001b[0m \u001b[37m□\u001b[0m \u001b[37m□\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(m):\n",
    "    df = pd.DataFrame(m)\n",
    "    df.set_index('trial', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorridorAdapter(EnvironmentAdapter):\n",
    "    @staticmethod\n",
    "    def to_genotype(phenotype):\n",
    "        return phenotype,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lcs.agents.acs2 as acs2\n",
    "\n",
    "acs2_cfg = acs2.Configuration(8, 8,\n",
    "                              epsilon=0.99,\n",
    "                              metrics_trial_frequency=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs2_agent = acs2.ACS2(cfg=acs2_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 7.22 ms, total: 16.8 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# explore\n",
    "pop_acs2_explr, m_acs2_explr = acs2_agent.explore(env, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pop_acs2_explr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####.F.#-5-####OOO#\tq: 1.0\tr: 999.95\n",
      "####F#.#-4-####O#O#\tq: 1.0\tr: 999.90\n",
      "###F##.#-3-###.##O#\tq: 1.0\tr: 999.86\n",
      "####.##F-7-####O##.\tq: 1.0\tr: 999.89\n",
      "###FO#.#-3-###.##O#\tq: 1.0\tr: 999.72\n",
      "##...#F#-6-####O#O#\tq: 1.0\tr: 998.81\n",
      "####.#F#-6-####O#O#\tq: 1.0\tr: 998.85\n",
      "###..#F#-6-####O#O#\tq: 1.0\tr: 998.81\n",
      "##.O..##-6-###.#F##\tq: 1.0\tr: 949.36\n",
      "#..O..##-6-###.#F##\tq: 1.0\tr: 949.36\n",
      ".O.##.##-5-#.###F##\tq: 1.0\tr: 949.32\n",
      ".O..#.#.-5-#.###F##\tq: 1.0\tr: 949.32\n",
      ".O.##.#.-5-#.###F##\tq: 1.0\tr: 949.32\n",
      "OO#...#.-3-..#FOO##\tq: 1.0\tr: 949.16\n",
      "#.OO#.##-7-##..#F##\tq: 1.0\tr: 948.95\n"
     ]
    }
   ],
   "source": [
    "reliable = [cl for cl in pop_acs2_explr if cl.is_reliable()]\n",
    "\n",
    "for cl in sorted(reliable, key=lambda cl: -cl.fitness)[:15]:\n",
    "    print(f'{cl.condition}-{cl.action}-{cl.effect}\\tq: {cl.q:.2}\\tr: {cl.r:06.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm_explr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-130ee9802eac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_explr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm_explr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mavg_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_explr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'steps_in_trial'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Average steps to reward {avg_steps:.2f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm_explr' is not defined"
     ]
    }
   ],
   "source": [
    "df_explr = to_df(m_explr)\n",
    "avg_steps = df_explr['steps_in_trial'].mean()\n",
    "print(f'Average steps to reward {avg_steps:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# exploit\n",
    "acs2_agent_exploit = acs2.ACS2(population=pop_acs2_explr, cfg=acs2_cfg)\n",
    "pop_explt, m_explt = agent.exploit(env, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_explt = to_df(m_explt)\n",
    "avg_steps = df_explt['steps_in_trial'].mean()\n",
    "print(f'Average steps to reward {avg_steps:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lcs.agents.aacs2 as aacs2\n",
    "\n",
    "aacs2_cfg = aacs2.Configuration(1, 2,\n",
    "                                epsilon=0.2,\n",
    "                                rho_update_version='2',\n",
    "                                user_metrics_collector_fcn=common_metrics,\n",
    "                                environment_adapter=CorridorAdapter,\n",
    "                                metrics_trial_frequency=1)\n",
    "\n",
    "aacs2_agent = aacs2.AACS2(cfg=aacs2_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# explore\n",
    "pop_explr, m_explr = aacs2_agent.explore(env, 10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aacs2_explr = to_df(m_explr)\n",
    "aacs2_avg_steps = df_aacs2_explr['steps_in_trial'].mean()\n",
    "print(f'Average steps to reward {aacs2_avg_steps:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aacs2_explr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# exploit\n",
    "aacs2_agent_exploit = aacs2.AACS2(population=pop_explr, cfg=aacs2_cfg)\n",
    "pop_aacs2_explt, m_aacs2_explt = aacs2_agent_exploit.exploit(env, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aacs2_explt = to_df(m_aacs2_explt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_steps = df_aacs2_explt['steps_in_trial'].mean()\n",
    "print(f'Average steps to reward {avg_steps:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
